{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMPT 423/820 \n",
    "## Assignment 1 Question 8\n",
    "* Seyedeh Mina Mousavifar\n",
    "* 11279515\n",
    "* sem311"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task\n",
    "Derive $P(y|\\mathbf{X}_1,\\mathbf{X}_2) = \\frac{m_1+m_2+a}{N_1+N_2+a+b}$\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on *Conditional Probability* formula we have:\n",
    "\n",
    "$$\n",
    "P(\\mu|\\mathbf{X}_1,\\mathbf{X}_2) = \n",
    "\\frac{P(\\mu, \\mathbf{X}_1,\\mathbf{X}_2)}{P(\\mathbf{X}_1,\\mathbf{X}_2)}\n",
    "$$\n",
    "\n",
    "\n",
    "Because of *Commutative property of Intersection* we can rewrite the equation as:\n",
    "\n",
    "\n",
    "$$\n",
    "P(\\mu|\\mathbf{X}_1,\\mathbf{X}_2) = \n",
    "\\frac{P(\\mathbf{X}_2, \\mu, \\mathbf{X}_1)}{P(\\mathbf{X}_1,\\mathbf{X}_2)}\n",
    "$$\n",
    "\n",
    "\n",
    "In order to obtain yesterday knowledge, we apply *Bayes' Rule* for $P(\\mathbf{X}_2, \\mu, \\mathbf{X}_1)$:\n",
    "\n",
    "\n",
    "$$\n",
    "P(\\mu|\\mathbf{X}_1,\\mathbf{X}_2) = \n",
    "\\frac{P(\\mathbf{X}_2|\\mu,\\mathbf{X}_1)\\;P(\\mu, \\mathbf{X}_1)}{P(\\mathbf{X}_1,\\mathbf{X}_2)}\n",
    "$$\n",
    "\n",
    "\n",
    "Applying *Conditional Probability* formula for $P(\\mu,\\mathbf{X}_1)$:\n",
    "\n",
    "\n",
    "$$\n",
    "P(\\mu|\\mathbf{X}_1,\\mathbf{X}_2) = \\frac{P(\\mathbf{X}_2|\\mu,\\mathbf{X}_1)\\;P(\\mu|\\mathbf{X}_1)\\;P(\\mathbf{X}_1)}{P(\\mathbf{X}_1,\\mathbf{X}_2)}\n",
    "$$\n",
    "\n",
    "\n",
    "As we can see, we have obtained our prior knowledge, which is $P(\\mu|\\mathbf{X}_1)$. \n",
    "\n",
    "<br>\n",
    "\n",
    "If we apply *Conditional Probability* formula for $P(\\mathbf{X}_2|\\mathbf{X}_1)$, we will have:\n",
    "\n",
    "\n",
    "$$\n",
    "P(\\mu|\\mathbf{X}_1,\\mathbf{X}_2) = \n",
    "\\frac{P(\\mathbf{X}_2|\\mu,\\mathbf{X}_1)\\;P(\\mu|\\mathbf{X}_1)}{\\frac{P(\\mathbf{X}_1,\\mathbf{X}_2)}{P(\\mathbf{X}_1)}} = \n",
    "\\frac{P(\\mathbf{X}_2|\\mu,\\mathbf{X}_1)\\;P(\\mu|\\mathbf{X}_1)}{P(\\mathbf{X}_2|\\mathbf{X}_1)}\n",
    "$$\n",
    "\n",
    "\n",
    "Considering the term $P(\\mu,\\mathbf{X}_1)$, we have already estimated $\\mu$ based on $\\mathbf{X}_1$, so we can infer that $\\mu$ convey $\\mathbf{X}_1$ in itself, and we can omit $\\mathbf{X}_1$.\n",
    "\n",
    "\n",
    "$$\n",
    "\\underline{\n",
    "P(\\mu|\\mathbf{X}_1,\\mathbf{X}_2) = \n",
    "\\frac{P(\\mathbf{X}_2|\\mu)\\;P(\\mu|\\mathbf{X}_1)}{P(\\mathbf{X}_2|\\mathbf{X}_1)}\n",
    "}\n",
    "$$\n",
    "\n",
    "\n",
    "As we can see in the above equation, likelihood is $P(\\mathbf{X}_2|\\mu)$, prior probability is $P(\\mu|\\mathbf{X}_1)$, and $P(\\mathbf{X}_2|\\mathbf{X}_1)$ is the normalization constant. Besides:\n",
    "\n",
    "\n",
    "$$\n",
    "P(\\mathbf{X}_2|\\mu) = Bin(m_2| N_2, \\mu) \\quad Binomial \\; distribution\\\\\n",
    "P(\\mu|\\mathbf{X}_1) = Beta((\\mu|\\mathbf{X}_1)|a', b') \\quad Beta \\; distribution\\\\\n",
    "$$\n",
    "\n",
    "\n",
    "Above, we can see that our knowledge of yesterday, has changed our prior Beta distribution. So, we will be more biased toward yesterday data, and add that info to our prior bias. So:\n",
    "\n",
    "\n",
    "$$\n",
    "P(\\mu|\\mathbf{X}_1) = Beta((\\mu|\\mathbf{X}_1)|a', b') \\quad a'=a+m_1 \\;,\\quad b' = b+N_1-m_1\\\\\n",
    "\\Rightarrow P(\\mu|\\mathbf{X}_1) = Beta((\\mu|\\mathbf{X}_1)|a+m_1, b+N_1-m_1)\n",
    "$$\n",
    "\n",
    "\n",
    "So for finding the final result, we have:\n",
    "\n",
    "\n",
    "$$\n",
    "P(\\mu|\\mathbf{X}_1,\\mathbf{X}_2) = \n",
    "\\frac{P(\\mathbf{X}_2|\\mu)\\;P(\\mu|\\mathbf{X}_1)}{P(\\mathbf{X}_2|\\mathbf{X}_1)}\\\\\n",
    "\\Rightarrow\n",
    "P(y|\\mathbf{X}_1,\\mathbf{X}_2) = E[\\mu|\\mathbf{X}_1,\\mathbf{X}_2] = \\int_{\\mu}\\mu\\frac{P(\\mathbf{X}_2|\\mu)\\;P(\\mu|\\mathbf{X}_1)}{P(\\mathbf{X}_2|\\mathbf{X}_1)}d\\mu\n",
    "$$\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "We have seen that:\n",
    "\n",
    "$$\n",
    "P(y|\\mathbf{X})=\\int_{\\mu}\\mu\\frac{P(\\mathbf{X})P(\\mu)}{P(\\mathbf{X})}d\\mu\n",
    "=\\frac{m+a}{N+a+b}\n",
    "$$\n",
    "\n",
    "So we infer that the integral, would give the same result, only with new parameters, which were discussed above:\n",
    "\n",
    "$$\n",
    "P(y|\\mathbf{X}_1,\\mathbf{X}_2) = E[\\mu|\\mathbf{X}_1,\\mathbf{X}_2] = \\int_{\\mu}\\mu\\frac{P(\\mathbf{X}_2|\\mu)\\;P(\\mu|\\mathbf{X}_1)}{P(\\mathbf{X}_2|\\mathbf{X}_1)}d\\mu=\\\\\n",
    "\\frac{m_2+a'}{N_2+a'+b'} = \\frac{m_2+m_1+a}{N_2+m_1+a+N_1-m_1+b} = \\frac{m_2+m_1+a}{N_2+N_1+a+b}\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
