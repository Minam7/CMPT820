
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass[11pt]{article}

    
    
    \usepackage[T1]{fontenc}
    % Nicer default font (+ math font) than Computer Modern for most use cases
    \usepackage{mathpazo}

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    

    
    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatability definitions
    \def\gt{>}
    \def\lt{<}
    % Document parameters
    \title{A2Q4}
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    \hypertarget{cmpt-423820}{%
\section{CMPT 423/820}\label{cmpt-423820}}

\hypertarget{assignment-2-question-4}{%
\subsection{Assignment 2 Question 4}\label{assignment-2-question-4}}

\begin{itemize}
\tightlist
\item
  Seyedeh Mina Mousavifar
\item
  11279515
\item
  sem311
\end{itemize}

    \hypertarget{theoretically}{%
\subsubsection{Theoretically}\label{theoretically}}

    \[
P(w_j|\mathbf{x}_i) = \frac{P(\mathbf{x}_i|w_j)P(w_j)}{P(\mathbf{x}_i)}
\]

where

\(\mathbf{x}_i\) is the feature vector of sample \(i\),
\(i \in {1,2,...,n}\),

\(w_j\) is the notation of class \(j\), \(j \in {1,2,...,m}\),

\(P(\mathbf{x}_i|w_j)\) is the probability of observing sample
\(\mathbf{x}_i\) given that it belongs to class \(w_j\).

So the decision rule is:

\[
predicted \; class \; label \leftarrow arg \; max \; P(w_j|\mathbf{x}_i) \quad for \; j=1,...,m
\]

Further, the class condition probilities of individual features \(d\)
are as follows because of \emph{naive} conditional independence
assumption.

\[
P(\mathbf{x}|w_j) = P(x_1|w_j)...P(x_d|w_j) = \Pi_{k=1}^{d}P(x_k|w_j)
\]

Another assumption of \emph{Naive Bayes} is that \(P(x_i=b|w_j)\) is
drawn from a particular distribution, which is the reason of calling
\emph{Naive Bayes} a \emph{generative model}.

    \hypertarget{bernoulli-model}{%
\paragraph{Bernoulli Model}\label{bernoulli-model}}

    We use the \emph{Bernoulli distribution} to compute the likelihood of a
binary variable. For example, we could estimate \(P(x_k=1 | w_j)\) via
\emph{MLE} as the frequency of occurences in the training set:

\[
\theta = P(x_k=1|w_j) = N_{x_k, w_j} / N_{w_j}
\]

This means, number of training samples in class \(w_j\) that have the
property \(x_k=1\) noted by \(N_{x_k, w_j}\) divided by by all training
samples in ωj, noted by \(N_{w_j}\).

\[
P(\mathbf{x}|w_j) = \Pi_{k=1}^{d}P(x_k|w_j) \quad (1.1)
\]

\[
P(\mathbf{x}|w_j) = \Pi_{k=1}^{d}(\theta^{x_k}(1-\theta)^{1-x_k})
\]

    \hypertarget{gaussian-model}{%
\paragraph{Gaussian Model}\label{gaussian-model}}

    Typically, the \emph{Gaussian Naive Bayes} model is used for variables
on a continuous scale, assuming that the variables are normally
distributed.

\[
P(x_k|w_j) = \frac{1}{\sqrt{2\pi\sigma_{w_j}^{2}}}exp(-\frac{(x_k - \mu_{w_j})^2}{2\sigma_{w_j}^{2}})
\]

Therefore, we need to estimate mean \(\mu\) of the samples associated
with class \(w_j\) and the variance \(\sigma^2\) associated with class
\(w_j\).

\[
P(\mathbf{x}|w_j) = \Pi_{k=1}^{d}P(x_k|w_j) \quad (1.2)
\]

    \hypertarget{mixed-model}{%
\paragraph{Mixed Model}\label{mixed-model}}

    Since \emph{Naive Bayes} assumes conditional independence between
features, it can be written as:

\[
P(\mathbf{x}|w_j) = \Pi_{k=1}^{d}P(x_k|w_j)
\]

By assuming that features \(a, ..., b\) are from \emph{Bernoulli}
distribution and the rest are from \emph{Guassian} distribution, we can
write the above equation as:

\[
P(\mathbf{x}|w_j) = \Pi_{k=a}^{b}P(x_k|w_j)\Pi_{k=b+1}^{d}P(x_k|w_j)
\]

So considering equation \((1.1)\), and \((1.2)\) the equation would be:

\[
P(\mathbf{x}|w_j) = P(\mathbf{x}_{bernoulli}|w_j)P(\mathbf{x}_{guassian}|w_j)
\]

This can also be applied to \emph{Multinoulli} instead of
\emph{Bernoulli} distribution.

    \hypertarget{practically}{%
\subsubsection{Practically}\label{practically}}

    For this part, I'll use \emph{Forest covertypes} dataset.

In this dataset, there are seven covertypes, making this a multiclass
classification problem. Each sample has 54 features, described
\href{https://archive.ics.uci.edu/ml/datasets/Covertype}{here}. Some of
the features are boolean indicators, while others are discrete or
continuous measurements.

It has 54 columns of data. 10 quantitative variables, 4 binary
wilderness areas and 40 binary soil type variables.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}59}]:} \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{datasets} \PY{k}{import} \PY{n}{fetch\PYZus{}covtype}
         \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
         
         \PY{n}{covtype} \PY{o}{=} \PY{n}{fetch\PYZus{}covtype}\PY{p}{(}\PY{p}{)}
         
         \PY{n}{data} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{o}{.}\PY{n}{from\PYZus{}records}\PY{p}{(}\PY{n}{covtype}\PY{o}{.}\PY{n}{data}\PY{p}{)}
         \PY{n}{labels} \PY{o}{=} \PY{n}{covtype}\PY{o}{.}\PY{n}{target}
         
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{covtype}\PY{o}{.}\PY{n}{DESCR}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
.. \_covtype\_dataset:

Forest covertypes
-----------------

The samples in this dataset correspond to 30×30m patches of forest in the US,
collected for the task of predicting each patch's cover type,
i.e. the dominant species of tree.
There are seven covertypes, making this a multiclass classification problem.
Each sample has 54 features, described on the
`dataset's homepage <https://archive.ics.uci.edu/ml/datasets/Covertype>`\_\_.
Some of the features are boolean indicators,
while others are discrete or continuous measurements.

**Data Set Characteristics:**

    =================   ============
    Classes                        7
    Samples total             581012
    Dimensionality                54
    Features                     int
    =================   ============

:func:`sklearn.datasets.fetch\_covtype` will load the covertype dataset;
it returns a dictionary-like object
with the feature matrix in the ``data`` member
and the target values in ``target``.
The dataset will be downloaded from the web if necessary.


    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}157}]:} \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k}{import} \PY{n}{train\PYZus{}test\PYZus{}split}
          
          \PY{c+c1}{\PYZsh{} Set aside  data as a part of test set}
          \PY{n}{tpropn} \PY{o}{=} \PY{l+m+mf}{0.2}
          \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{Y\PYZus{}train}\PY{p}{,} \PY{n}{Y\PYZus{}test} \PY{o}{=} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{data}\PY{p}{,} 
                                                              \PY{n}{labels}\PY{p}{,} 
                                                              \PY{n}{test\PYZus{}size}\PY{o}{=}\PY{n}{tpropn}\PY{p}{)}
          
          
          \PY{c+c1}{\PYZsh{} continues part of train data}
          \PY{n}{data\PYZus{}con} \PY{o}{=} \PY{n}{X\PYZus{}train}\PY{o}{.}\PY{n}{values}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{p}{:}\PY{l+m+mi}{10}\PY{p}{]}
          \PY{n}{test\PYZus{}con} \PY{o}{=} \PY{n}{X\PYZus{}test}\PY{o}{.}\PY{n}{values}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{p}{:}\PY{l+m+mi}{10}\PY{p}{]}
          
          \PY{c+c1}{\PYZsh{} discrete part of train data}
          \PY{n}{data\PYZus{}cat} \PY{o}{=} \PY{n}{X\PYZus{}train}\PY{o}{.}\PY{n}{values}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{l+m+mi}{10}\PY{p}{:}\PY{p}{]}
          \PY{n}{test\PYZus{}cat} \PY{o}{=} \PY{n}{X\PYZus{}test}\PY{o}{.}\PY{n}{values}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{l+m+mi}{10}\PY{p}{:}\PY{p}{]}
\end{Verbatim}


    I independently fit a \emph{Gaussian NB model} on the continuous part of
the data and a \emph{Multinomial NB model} on the categorical part. Then
transform all the dataset by taking the class assignment probabilities,
with \emph{predict\_proba} method. Then I multiply these probabilities
and find the most probability for each record, as predicted label.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}161}]:} \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{naive\PYZus{}bayes} \PY{k}{import} \PY{n}{CategoricalNB}\PY{p}{,} \PY{n}{GaussianNB}
          \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
          
          \PY{c+c1}{\PYZsh{} fitting model for categorical part}
          \PY{n}{clf\PYZus{}cat} \PY{o}{=} \PY{n}{CategoricalNB}\PY{p}{(}\PY{p}{)}
          \PY{n}{clf\PYZus{}cat}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{data\PYZus{}cat}\PY{p}{,} \PY{n}{Y\PYZus{}train}\PY{p}{)}
          
          \PY{c+c1}{\PYZsh{} fitting model for continuous part}
          \PY{n}{clf\PYZus{}con} \PY{o}{=} \PY{n}{GaussianNB}\PY{p}{(}\PY{p}{)}
          \PY{n}{clf\PYZus{}con}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{data\PYZus{}con}\PY{p}{,} \PY{n}{Y\PYZus{}train}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}161}]:} GaussianNB(priors=None, var\_smoothing=1e-09)
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}162}]:} \PY{k}{def} \PY{n+nf}{mixed\PYZus{}predictor}\PY{p}{(}\PY{n}{model\PYZus{}cat}\PY{p}{,}
                              \PY{n}{model\PYZus{}con}\PY{p}{,}
                              \PY{n}{data\PYZus{}in\PYZus{}cat}\PY{p}{,}
                              \PY{n}{data\PYZus{}in\PYZus{}con}\PY{p}{)}\PY{p}{:}
              \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
          \PY{l+s+sd}{    :purpose: This function find class labels with}
          \PY{l+s+sd}{     Naive Bayes classifier on mixed class.}
          \PY{l+s+sd}{    :param model\PYZus{}cat: learned categorical NB}
          \PY{l+s+sd}{    :param model\PYZus{}cat: learned continuous NB}
          \PY{l+s+sd}{    :param data\PYZus{}in\PYZus{}cat: categorical part of dataset}
          \PY{l+s+sd}{    :param data\PYZus{}in\PYZus{}con: continues part of dataset}
          \PY{l+s+sd}{    :return: labels on the dataset}
          \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
              \PY{n}{prob\PYZus{}cat} \PY{o}{=} \PY{n}{model\PYZus{}cat}\PY{o}{.}\PY{n}{predict\PYZus{}proba}\PY{p}{(}\PY{n}{data\PYZus{}in\PYZus{}cat}\PY{p}{)}
              \PY{n}{prob\PYZus{}con} \PY{o}{=} \PY{n}{model\PYZus{}con}\PY{o}{.}\PY{n}{predict\PYZus{}proba}\PY{p}{(}\PY{n}{data\PYZus{}in\PYZus{}con}\PY{p}{)}
              \PY{n}{new\PYZus{}feature} \PY{o}{=} \PY{n}{prob\PYZus{}cat}\PY{o}{*}\PY{n}{prob\PYZus{}con}
          
              \PY{c+c1}{\PYZsh{} prediction based on probabilites}
              \PY{n}{new\PYZus{}feature} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{new\PYZus{}feature}\PY{p}{,}
                           \PY{n}{columns}\PY{o}{=}\PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{8}\PY{p}{)}\PY{p}{)}
          
              \PY{n}{new\PYZus{}feature}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{pred\PYZus{}label}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{new\PYZus{}feature}\PY{o}{.}\PY{n}{idxmax}\PY{p}{(}\PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
          
              \PY{k}{return} \PY{n}{new\PYZus{}feature}\PY{o}{.}\PY{n}{pred\PYZus{}label}\PY{o}{.}\PY{n}{values}
\end{Verbatim}


    \hypertarget{evaluation}{%
\paragraph{Evaluation}\label{evaluation}}

For evaluation I compare this model with \emph{Guassian NB} and
\emph{Categorical NB} classifier.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}166}]:} \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{metrics} \PY{k}{import} \PY{n}{accuracy\PYZus{}score}
          \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{metrics} \PY{k}{import} \PY{n}{f1\PYZus{}score}
          
          \PY{c+c1}{\PYZsh{} on training set}
          \PY{n}{y\PYZus{}predicted} \PY{o}{=} \PY{n}{mixed\PYZus{}predictor}\PY{p}{(}\PY{n}{clf\PYZus{}cat}\PY{p}{,}
                                        \PY{n}{clf\PYZus{}con}\PY{p}{,}
                                        \PY{n}{data\PYZus{}cat}\PY{p}{,}
                                        \PY{n}{data\PYZus{}con}\PY{p}{)}
          \PY{n}{f1} \PY{o}{=} \PY{n}{f1\PYZus{}score}\PY{p}{(}\PY{n}{Y\PYZus{}train}\PY{p}{,}
                        \PY{n}{y\PYZus{}predicted}\PY{p}{,}
                        \PY{n}{average}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{macro}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          
          \PY{n}{acc} \PY{o}{=} \PY{n}{accuracy\PYZus{}score}\PY{p}{(}\PY{n}{Y\PYZus{}train}\PY{p}{,}
                        \PY{n}{y\PYZus{}predicted}\PY{p}{)}
          
          \PY{c+c1}{\PYZsh{} printing result in tabular format}
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+se}{\PYZbs{}033}\PY{l+s+s1}{[1m}\PY{l+s+s1}{\PYZsq{}} \PY{o}{+} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Multi\PYZhy{}class NB classifier}\PY{l+s+s1}{\PYZsq{}} \PY{o}{+} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+se}{\PYZbs{}033}\PY{l+s+s1}{[0m}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZob{}:\PYZlt{}15\PYZcb{}}\PY{l+s+s1}{ }\PY{l+s+si}{\PYZob{}:\PYZlt{}15\PYZcb{}}\PY{l+s+s1}{ }\PY{l+s+si}{\PYZob{}:\PYZlt{}15\PYZcb{}}\PY{l+s+s1}{ }\PY{l+s+si}{\PYZob{}:\PYZlt{}15\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Predictor}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                                      \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                                      \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{F1\PYZhy{}score}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                                       \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
          
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZob{}:\PYZlt{}15\PYZcb{}}\PY{l+s+s1}{ }\PY{l+s+si}{\PYZob{}:\PYZlt{}15\PYZcb{}}\PY{l+s+s1}{ }\PY{l+s+si}{\PYZob{}:\PYZlt{}15\PYZcb{}}\PY{l+s+s1}{ }\PY{l+s+si}{\PYZob{}:\PYZlt{}15\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Mixed}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                                       \PY{n+nb}{round}\PY{p}{(}\PY{n}{acc}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{)}\PY{p}{,}
                                       \PY{n+nb}{round}\PY{p}{(}\PY{n}{f1}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{)}\PY{p}{,}
                                       \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{training set}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
          
          \PY{c+c1}{\PYZsh{} on test set}
          \PY{n}{y\PYZus{}predicted} \PY{o}{=} \PY{n}{mixed\PYZus{}predictor}\PY{p}{(}\PY{n}{clf\PYZus{}cat}\PY{p}{,}
                                        \PY{n}{clf\PYZus{}con}\PY{p}{,}
                                        \PY{n}{test\PYZus{}cat}\PY{p}{,}
                                        \PY{n}{test\PYZus{}con}\PY{p}{)}
          \PY{n}{f1} \PY{o}{=} \PY{n}{f1\PYZus{}score}\PY{p}{(}\PY{n}{Y\PYZus{}test}\PY{p}{,}
                        \PY{n}{y\PYZus{}predicted}\PY{p}{,}
                        \PY{n}{average}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{macro}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          
          \PY{n}{acc} \PY{o}{=} \PY{n}{accuracy\PYZus{}score}\PY{p}{(}\PY{n}{Y\PYZus{}test}\PY{p}{,}
                        \PY{n}{y\PYZus{}predicted}\PY{p}{)}
          
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZob{}:\PYZlt{}15\PYZcb{}}\PY{l+s+s1}{ }\PY{l+s+si}{\PYZob{}:\PYZlt{}15\PYZcb{}}\PY{l+s+s1}{ }\PY{l+s+si}{\PYZob{}:\PYZlt{}15\PYZcb{}}\PY{l+s+s1}{ }\PY{l+s+si}{\PYZob{}:\PYZlt{}15\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Mixed}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                                       \PY{n+nb}{round}\PY{p}{(}\PY{n}{acc}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{)}\PY{p}{,}
                                       \PY{n+nb}{round}\PY{p}{(}\PY{n}{f1}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{)}\PY{p}{,}
                                       \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{test set}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
          
          \PY{c+c1}{\PYZsh{} Guassian Naive Bayes Predictor}
          \PY{c+c1}{\PYZsh{} on training set}
          \PY{n}{y\PYZus{}predicted} \PY{o}{=} \PY{n}{clf\PYZus{}con}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{data\PYZus{}con}\PY{p}{)}
          
          \PY{n}{f1} \PY{o}{=} \PY{n}{f1\PYZus{}score}\PY{p}{(}\PY{n}{Y\PYZus{}train}\PY{p}{,}
                        \PY{n}{y\PYZus{}predicted}\PY{p}{,}
                        \PY{n}{average}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{macro}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          
          \PY{n}{acc} \PY{o}{=} \PY{n}{accuracy\PYZus{}score}\PY{p}{(}\PY{n}{Y\PYZus{}train}\PY{p}{,}
                        \PY{n}{y\PYZus{}predicted}\PY{p}{)}
          
          \PY{c+c1}{\PYZsh{} printing result in tabular format}
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZob{}:\PYZlt{}15\PYZcb{}}\PY{l+s+s1}{ }\PY{l+s+si}{\PYZob{}:\PYZlt{}15\PYZcb{}}\PY{l+s+s1}{ }\PY{l+s+si}{\PYZob{}:\PYZlt{}15\PYZcb{}}\PY{l+s+s1}{ }\PY{l+s+si}{\PYZob{}:\PYZlt{}15\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Guassian}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                                       \PY{n+nb}{round}\PY{p}{(}\PY{n}{acc}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{)}\PY{p}{,}
                                       \PY{n+nb}{round}\PY{p}{(}\PY{n}{f1}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{)}\PY{p}{,}
                                       \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{training set}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
          
          \PY{n}{y\PYZus{}predicted} \PY{o}{=} \PY{n}{clf\PYZus{}con}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{test\PYZus{}con}\PY{p}{)}
          
          \PY{n}{f1} \PY{o}{=} \PY{n}{f1\PYZus{}score}\PY{p}{(}\PY{n}{Y\PYZus{}test}\PY{p}{,}
                        \PY{n}{y\PYZus{}predicted}\PY{p}{,}
                        \PY{n}{average}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{macro}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          
          \PY{n}{acc} \PY{o}{=} \PY{n}{accuracy\PYZus{}score}\PY{p}{(}\PY{n}{Y\PYZus{}test}\PY{p}{,}
                        \PY{n}{y\PYZus{}predicted}\PY{p}{)}
          
          \PY{c+c1}{\PYZsh{} printing result in tabular format}
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZob{}:\PYZlt{}15\PYZcb{}}\PY{l+s+s1}{ }\PY{l+s+si}{\PYZob{}:\PYZlt{}15\PYZcb{}}\PY{l+s+s1}{ }\PY{l+s+si}{\PYZob{}:\PYZlt{}15\PYZcb{}}\PY{l+s+s1}{ }\PY{l+s+si}{\PYZob{}:\PYZlt{}15\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Guassian}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                                       \PY{n+nb}{round}\PY{p}{(}\PY{n}{acc}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{)}\PY{p}{,}
                                       \PY{n+nb}{round}\PY{p}{(}\PY{n}{f1}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{)}\PY{p}{,} 
                                       \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{test set}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
          
          \PY{c+c1}{\PYZsh{} Categorical Naive Bayes Predictor}
          \PY{c+c1}{\PYZsh{} on training set}
          \PY{n}{y\PYZus{}predicted} \PY{o}{=} \PY{n}{clf\PYZus{}cat}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{data\PYZus{}cat}\PY{p}{)}
          
          \PY{n}{f1} \PY{o}{=} \PY{n}{f1\PYZus{}score}\PY{p}{(}\PY{n}{Y\PYZus{}train}\PY{p}{,}
                        \PY{n}{y\PYZus{}predicted}\PY{p}{,}
                        \PY{n}{average}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{macro}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          
          \PY{n}{acc} \PY{o}{=} \PY{n}{accuracy\PYZus{}score}\PY{p}{(}\PY{n}{Y\PYZus{}train}\PY{p}{,}
                        \PY{n}{y\PYZus{}predicted}\PY{p}{)}
          
          \PY{c+c1}{\PYZsh{} printing result in tabular format}
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZob{}:\PYZlt{}15\PYZcb{}}\PY{l+s+s1}{ }\PY{l+s+si}{\PYZob{}:\PYZlt{}15\PYZcb{}}\PY{l+s+s1}{ }\PY{l+s+si}{\PYZob{}:\PYZlt{}15\PYZcb{}}\PY{l+s+s1}{ }\PY{l+s+si}{\PYZob{}:\PYZlt{}15\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Categorical}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                                       \PY{n+nb}{round}\PY{p}{(}\PY{n}{acc}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{)}\PY{p}{,}
                                       \PY{n+nb}{round}\PY{p}{(}\PY{n}{f1}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{)}\PY{p}{,}
                                       \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{training set}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
          
          \PY{n}{y\PYZus{}predicted} \PY{o}{=} \PY{n}{clf\PYZus{}cat}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{test\PYZus{}cat}\PY{p}{)}
          
          \PY{n}{f1} \PY{o}{=} \PY{n}{f1\PYZus{}score}\PY{p}{(}\PY{n}{Y\PYZus{}test}\PY{p}{,}
                        \PY{n}{y\PYZus{}predicted}\PY{p}{,}
                        \PY{n}{average}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{macro}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          
          \PY{n}{acc} \PY{o}{=} \PY{n}{accuracy\PYZus{}score}\PY{p}{(}\PY{n}{Y\PYZus{}test}\PY{p}{,}
                        \PY{n}{y\PYZus{}predicted}\PY{p}{)}
          
          \PY{c+c1}{\PYZsh{} printing result in tabular format}
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZob{}:\PYZlt{}15\PYZcb{}}\PY{l+s+s1}{ }\PY{l+s+si}{\PYZob{}:\PYZlt{}15\PYZcb{}}\PY{l+s+s1}{ }\PY{l+s+si}{\PYZob{}:\PYZlt{}15\PYZcb{}}\PY{l+s+s1}{ }\PY{l+s+si}{\PYZob{}:\PYZlt{}15\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Categorical}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                                       \PY{n+nb}{round}\PY{p}{(}\PY{n}{acc}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{)}\PY{p}{,}
                                       \PY{n+nb}{round}\PY{p}{(}\PY{n}{f1}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{)}\PY{p}{,}
                                       \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{test set}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
\textbf{Multi-class NB classifier}
Predictor       Accuracy        F1-score        type           
Mixed           0.68043         0.48956         training set   
Mixed           0.67989         0.48803         test set       
Guassian        0.63047         0.44924         training set   
Guassian        0.62923         0.44694         test set       
Categorical     0.63226         0.48263         training set   
Categorical     0.63312         0.48605         test set       

    \end{Verbatim}

    So we can see that we have better accuracy and f1-score for mixed
classifier.


    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
