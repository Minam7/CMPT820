{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMPT 423/820 \n",
    "## Assignment 2 Question 4\n",
    "* Seyedeh Mina Mousavifar\n",
    "* 11279515\n",
    "* sem311"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theoretically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "P(w_j|\\mathbf{x}_i) = \\frac{P(\\mathbf{x}_i|w_j)P(w_j)}{P(\\mathbf{x}_i)}\n",
    "$$\n",
    "\n",
    "\n",
    "where\n",
    "\n",
    "$\\mathbf{x}_i$ is the feature vector of sample $i$, $i \\in {1,2,...,n}$,\n",
    "\n",
    "$w_j$ is the notation of class $j$, $j \\in {1,2,...,m}$,\n",
    "\n",
    "$P(\\mathbf{x}_i|w_j)$ is the probability of observing sample $\\mathbf{x}_i$ given that it belongs to class $w_j$.\n",
    "\n",
    "\n",
    "So the decision rule is:\n",
    "\n",
    "$$\n",
    "predicted \\; class \\; label \\leftarrow arg \\; max \\; P(w_j|\\mathbf{x}_i) \\quad for \\; j=1,...,m\n",
    "$$\n",
    "\n",
    "Further, the class condition probilities of individual features $d$ are as follows because of *naive* conditional independence assumption.\n",
    "\n",
    "$$\n",
    "P(\\mathbf{x}|w_j) = P(x_1|w_j)...P(x_d|w_j) = \\Pi_{k=1}^{d}P(x_k|w_j)\n",
    "$$\n",
    "\n",
    "Another assumption of *Naive Bayes* is that $P(x_i=b|w_j)$ is drawn from a particular distribution, which is the reason of calling *Naive Bayes* a *generative model*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bernoulli Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the *Bernoulli distribution* to compute the likelihood of a binary variable. For example, we could estimate $P(x_k=1 | w_j)$ via *MLE* as the frequency of occurences in the training set:\n",
    "\n",
    "$$\n",
    "\\theta = P(x_k=1|w_j) = N_{x_k, w_j} / N_{w_j}\n",
    "$$\n",
    "\n",
    "This means, number of training samples in class $w_j$ that have the property $x_k=1$ noted by $N_{x_k, w_j}$ divided by by all training samples in ωj, noted by $N_{w_j}$.\n",
    "\n",
    "$$\n",
    "P(\\mathbf{x}|w_j) = \\Pi_{k=1}^{d}P(x_k|w_j)\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(\\mathbf{x}|w_j) = \\Pi_{k=1}^{d}(\\theta^{x_k}(1-\\theta)^{1-x_k})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, the *Gaussian Naive Bayes* model is used for variables on a continuous scale, assuming that the variables are normally distributed.\n",
    "\n",
    "$$\n",
    "P(x_k|w_j) = \\frac{1}{\\sqrt{2\\pi\\sigma_{w_j}^{2}}}exp(-\\frac{(x_k - \\mu_{w_j})^2}{2\\sigma_{w_j}^{2}})\n",
    "$$\n",
    "\n",
    "Therefore, we need to estimate mean $\\mu$ of the samples associated with class $w_j$ and the variance $\\sigma^2$ associated with class $w_j$.\n",
    "\n",
    "$$\n",
    "P(\\mathbf{x}|w_j) = \\Pi_{k=1}^{d}P(x_k|w_j)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since *Naive Bayes* assumes conditional independence between features, it can be written as:\n",
    "\n",
    "$$\n",
    "P(\\mathbf{x}|w_j) = P(\\mathbf{x}_{bernoulli}|w_j)P(\\mathbf{x}_{guassian}|w_j)\n",
    "$$\n",
    "\n",
    "This can also be applied to *Multinoulli* instead of *bernoulli* distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this part, I'll use *Forest covertypes* dataset. \n",
    "\n",
    "In this dataset, there are seven covertypes, making this a multiclass classification problem. Each sample has 54 features, described [here](https://archive.ics.uci.edu/ml/datasets/Covertype). Some of the features are boolean indicators, while others are discrete or continuous measurements.\n",
    "\n",
    "It has 54 columns of data. 10 quantitative variables, 4 binary wilderness areas and 40 binary soil type variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _covtype_dataset:\n",
      "\n",
      "Forest covertypes\n",
      "-----------------\n",
      "\n",
      "The samples in this dataset correspond to 30×30m patches of forest in the US,\n",
      "collected for the task of predicting each patch's cover type,\n",
      "i.e. the dominant species of tree.\n",
      "There are seven covertypes, making this a multiclass classification problem.\n",
      "Each sample has 54 features, described on the\n",
      "`dataset's homepage <https://archive.ics.uci.edu/ml/datasets/Covertype>`__.\n",
      "Some of the features are boolean indicators,\n",
      "while others are discrete or continuous measurements.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    =================   ============\n",
      "    Classes                        7\n",
      "    Samples total             581012\n",
      "    Dimensionality                54\n",
      "    Features                     int\n",
      "    =================   ============\n",
      "\n",
      ":func:`sklearn.datasets.fetch_covtype` will load the covertype dataset;\n",
      "it returns a dictionary-like object\n",
      "with the feature matrix in the ``data`` member\n",
      "and the target values in ``target``.\n",
      "The dataset will be downloaded from the web if necessary.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_covtype\n",
    "import pandas as pd\n",
    "\n",
    "covtype = fetch_covtype()\n",
    "\n",
    "data = pd.DataFrame.from_records(covtype.data)\n",
    "labels = covtype.target\n",
    "\n",
    "print(covtype.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continues part of data\n",
    "data_con = data.values[:, :10]\n",
    "\n",
    "# discrete part of data\n",
    "data_cat = data.values[:, 10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Independently fit a gaussian NB model on the continuous part of the data and a multinomial NB model on the categorical part. Then transform all the dataset by taking the class assignment probabilities (with predict_proba method) as new features: np.hstack((multinomial_probas, gaussian_probas)) and then refit a new model (e.g. a new gaussian NB) on the new features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(581012, 10)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_con.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
